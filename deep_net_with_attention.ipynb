{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "read dataset, \n",
    "and get the 'comment_text' column,\n",
    "create a stop_words instance, which is a set()\n",
    "'''\n",
    "#stemmer = SnowballStemmer('english')  # did not use stemmer\n",
    "stop_words = set(stopwords.words(\"english\"))   # set()\n",
    "\n",
    "# read raw file:  -> DataFrame\n",
    "train_set = pd.read_csv(\"./train.csv\")\n",
    "#train_set.head()\n",
    "test_set = pd.read_csv(\"./test.csv\")\n",
    "#test_set.head()\n",
    "\n",
    "# get the 'comment column':\n",
    "#train_text = train_set[\"comment_text\"]\n",
    "#test_text = test_set[\"comment_text\"]\n",
    "train_text = train_set.loc[:,\"comment_text\"]\n",
    "test_text = test_set.loc[:,\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "get the labels from training set: y,\n",
    "get each comment from all dataset,\n",
    "'''\n",
    "\n",
    "# get the comment in ndarrays and clean it:\n",
    "# Get labels arrays & train array:\n",
    "labels_list = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "get_labels = train_set[labels_list]  #-> DataFrame\n",
    "y = get_labels.values  #-> ndarray -> (159571,6)\n",
    "\n",
    "\n",
    "train_array = train_set[\"comment_text\"].values  # -> ndarray  (159571,)\n",
    "test_array = test_set[\"comment_text\"].values   # -> ndarray  (153164,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "create a fucntion to clean all comments,\n",
    "create two empty lists.\n",
    "'''\n",
    "# A list to store cleaned text\n",
    "train_cleaned_comment_list = [] \n",
    "test_cleaned_comment_list = []\n",
    "\n",
    "\n",
    "# set one peise of comment as para\n",
    "def clean_comment(comment):\n",
    "    # remove anything that are not words\n",
    "    re_train = str(re.sub(\"[^a-zA-Z]\",\" \", comment))\n",
    "    #print(retrain)\n",
    "    \n",
    "    # \n",
    "    tokened_train = word_tokenize(re_train.lower())\n",
    "    #print(tokened_train)\n",
    "    \n",
    "    # remove stop_words that have not contribution to the meaning\n",
    "    stoped_train = [_ for _ in tokened_train if _ not in stop_words]\n",
    "    #print(stoped_train)\n",
    "    \n",
    "    # connect words as a string\n",
    "    stoped_train_str = \" \".join(stoped_train) # -> string\n",
    "    \n",
    "    return stoped_train_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:53<00:00, 2996.05it/s]\n",
      "  0%|          | 301/153164 [00:00<00:50, 3007.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the list(train):  159571\n",
      "The number of commnents(train):  159571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [00:47<00:00, 3198.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the list(test):  153164\n",
      "The number of commnents(test):  153164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Input cleaned data into lists and files\n",
    "'''\n",
    "# write to filess\n",
    "count = 0\n",
    "my_file = open('./cleaned_train_comment.csv','w')\n",
    "for _ in tqdm(train_array):\n",
    "    i = clean_comment(_)\n",
    "    #print(i)\n",
    "    train_cleaned_comment_list.append(i)\n",
    "    my_file.write(i)\n",
    "    my_file.write('\\n')\n",
    "    count+=1\n",
    "my_file.close()\n",
    "print(\"The length of the list(train): \",len(train_cleaned_comment_list))\n",
    "print(\"The number of commnents(train): \", count)\n",
    "\n",
    "\n",
    "count = 0\n",
    "my_file = open('./cleaned_test_comment.csv','w')\n",
    "for _ in tqdm(test_array):\n",
    "    i = clean_comment(_)\n",
    "    #print(i)\n",
    "    test_cleaned_comment_list.append(i)\n",
    "    my_file.write(i)\n",
    "    my_file.write('\\n')\n",
    "    count+=1\n",
    "my_file.close()\n",
    "print(\"The length of the list(test): \",len(test_cleaned_comment_list))\n",
    "print(\"The number of commnents(test): \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For testing: 1000 data for testing\n",
    "'''\n",
    "\n",
    "#train_cleaned_comment_list = train_cleaned_comment_list[0:1000] \n",
    "#y = y[0:1000]\n",
    "# test_cleaned_comment_list = test_cleaned_comment_list[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cleaned_comment_list)\n",
    "len(test_cleaned_comment_list),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[629, 75, 51, 617, 4097, 7579, 1242, 301, 17234, 6013, 2302, 2499, 37, 1057, 15574, 2063, 8, 173, 254, 11, 3, 57, 4430]\n",
      "197276 unique words were found\n",
      "vec_train_data:  (1000, 100)\n",
      "vec_test_data:  (153164, 100)\n",
      "labels:  (1000, 6)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "vectorization,\n",
    "extend each comments to the same length, set maxlen=100,\n",
    "* note that only 1000 of training and testing data are selected.\n",
    "'''\n",
    "# vecterization:\n",
    "\n",
    "# we take only top 100000 words\n",
    "#take only words with an index less or equal to 100000\n",
    "tokenizer = Tokenizer(num_words=100000)    \n",
    "\n",
    "#calculate every appeared words, and index them\n",
    "tokenizer.fit_on_texts(train_cleaned_comment_list + test_cleaned_comment_list)   \n",
    "\n",
    "# replace all the words with their index that created from fit_on_texts() \n",
    "train_sequences = tokenizer.texts_to_sequences(train_cleaned_comment_list)  \n",
    "test_sequences = tokenizer.texts_to_sequences(test_cleaned_comment_list)\n",
    "\n",
    "# for testing\n",
    "# print(train_cleaned_comment_list)\n",
    "print(train_sequences[0])  \n",
    "\n",
    "# every word has an index,\n",
    "# it is needed for embedding.\n",
    "word_index = tokenizer.word_index  # len() -> 14121 \n",
    "print(\"%d unique words were found\"%len(word_index))\n",
    "\n",
    "# extend or shrink every piece comment to the lenght 100\n",
    "vec_train_data = pad_sequences(train_sequences, maxlen=100)   # ->(1000, 100)\n",
    "print(\"vec_train_data: \",vec_train_data.shape)      \n",
    "\n",
    "vec_test_data = pad_sequences(test_sequences, maxlen=100)    # ->(1000, 100)\n",
    "print(\"vec_test_data: \",vec_test_data.shape)\n",
    "print(\"labels: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storing these output\n",
    "'''\n",
    "###\n",
    "# Put vectorizing comments into and files\n",
    "###\n",
    "\n",
    "# write to filess\n",
    "count = 0\n",
    "my_file = open('./vec_train_comment.csv','w')\n",
    "for _ in tqdm(vec_train_data):\n",
    "    my_file.write(str(_))\n",
    "    my_file.write('\\n\\n\\n')\n",
    "    count+=1\n",
    "my_file.close()\n",
    "print(\"vec_train_data #: \", count)\n",
    "\n",
    "\n",
    "count = 0\n",
    "my_file = open('./vec_test_comment.csv','w')   \n",
    "for _ in tqdm(vec_test_data):\n",
    "    my_file.write(str(_))\n",
    "    my_file.write('\\n\\n\\n')\n",
    "    count+=1\n",
    "my_file.close()\n",
    "print(\"vec_test_data #: \", count)\n",
    "print(\"!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "split data into training set and validation set\n",
    "\"\"\"\n",
    "\n",
    "# shuffle all samples:\n",
    "shuffle_data = np.random.permutation(len(vec_train_data))   #->(1000, )\n",
    "\n",
    "# get the indeces of train & val:\n",
    "index_data_train = shuffle_data[: int(len(vec_train_data) * 0.9)]  # -> (900,)\n",
    "index_data_val = shuffle_data[int(len(vec_train_data) * 0.9) :]    # -> (100,)\n",
    "\n",
    "# training data  \n",
    "final_data_train = vec_train_data[index_data_train]  # -> (0.9*, maxlen)           #   (^_^)\n",
    "labels_train = y[index_data_train]      # labels      #-> (0.9*, 6)                #   (^_^)\n",
    "\n",
    "#validation data\n",
    "final_data_val = vec_train_data[index_data_val]     #->(0.1, maxlen)            #  (^_^)\n",
    "labels_val = y[index_data_val]                     # ->(0.1, 6)                 #  (^_^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_train #:  900\n",
      "final_validation #:  100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Input train and validation data into and files with their LABELS!!!\n",
    "'''\n",
    "# write to files\n",
    "count = 0\n",
    "with open('./final_train.csv','w') as my_file:\n",
    "    for _, _1 in zip(final_data_train, labels_train):     # write labels into 'final_train.csv'\n",
    "        my_file.write(str(_))\n",
    "        my_file.write(str(_1))\n",
    "        my_file.write('\\n\\n\\n')\n",
    "        count+=1\n",
    "my_file.close()\n",
    "print(\"final_train #: \", count) \n",
    "\n",
    "\n",
    "count = 0\n",
    "with open('./final_validation.csv','w') as my_file:\n",
    "    for _, _1 in zip(final_data_val, labels_val):\n",
    "        my_file.write(str(_))\n",
    "        my_file.write(str(_1))\n",
    "        my_file.write('\\n\\n\\n')\n",
    "        count+=1\n",
    "my_file.close()\n",
    "print(\"final_validation #: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What we need from above are :\n",
    "# vec_test_data            ->(1000,maxlen)\n",
    "# final_data_train         ->(0.9*, maxlen)\n",
    "# labels_train             ->(0.9*, 6)\n",
    "# final_data_val           ->(0.1*, maxlen)\n",
    "# labels_val               ->(0.1*, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# TRAIN_DATA_FILE = 'train.csv'\n",
    "# TEST_DATA_FILE = 'test.csv'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NB_WORDS = 100000\n",
    "EMBEDDING_DIM = 300 \n",
    "#VALIDATION_SPLIT = 0.9\n",
    "\n",
    "num_lstm = 300\n",
    "num_dense = 256\n",
    "rate_drop_lstm = 0.25\n",
    "rate_drop_dense = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [01:45, 20762.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embedding:\n",
    "embeddings_index = {}\n",
    "\n",
    "## https://nlp.stanford.edu/projects/glove/\n",
    "with open('../glove_matrix/glove.840B.300d.txt','rb') as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs      # -> 2196016\n",
    "f.close()\n",
    "\n",
    "\n",
    "# embeddings_index is a dict created by using 'glove_matrix'.\n",
    "# each 'key' in that dic has a 300D array as its 'value', which is generated by pre-training 'glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = list(embeddings_index.items() )    # len() 2196016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'proud', array([  1.17040001e-01,  -2.78840004e-03,  -2.43670009e-02,\n",
       "         -5.54220006e-02,   5.95059991e-01,  -2.40170002e-01,\n",
       "          5.70630014e-01,  -2.68220007e-01,  -1.82980001e-01,\n",
       "          2.44460011e+00,  -5.69869988e-02,  -7.23429993e-02,\n",
       "         -1.94299996e-01,  -4.10400003e-01,   1.55870005e-01,\n",
       "          2.94559985e-01,  -1.31139994e-01,   1.05300002e-01,\n",
       "         -1.52390003e-01,   3.91279995e-01,  -1.50100002e-02,\n",
       "         -6.86990023e-01,   1.39239997e-01,   2.54689991e-01,\n",
       "         -2.96530008e-01,  -9.79709998e-02,  -4.87399995e-01,\n",
       "         -2.47899994e-01,   1.23049997e-01,   2.10569993e-01,\n",
       "          1.52349994e-01,   6.14540018e-02,   1.58940002e-01,\n",
       "          1.69290006e-01,  -3.44119996e-01,  -1.31259993e-01,\n",
       "         -1.49320006e-01,   1.28169999e-01,  -3.30570012e-01,\n",
       "          1.65419996e-01,   1.33120000e-01,   1.96630001e-01,\n",
       "          3.83810014e-01,  -3.78840007e-02,   3.06380004e-01,\n",
       "         -2.43990004e-01,   2.53939986e-01,  -7.52289966e-02,\n",
       "          3.54369998e-01,   7.31649995e-02,  -1.66260004e-01,\n",
       "          7.83789977e-02,   5.61029986e-02,  -1.58130005e-01,\n",
       "          2.43709996e-01,   5.56429982e-01,  -3.26059997e-01,\n",
       "          5.09230018e-01,  -9.16889980e-02,  -5.79999983e-02,\n",
       "         -1.02069996e-01,  -5.09190023e-01,  -4.11229998e-01,\n",
       "         -7.35699981e-02,   1.23250000e-01,  -1.50110006e-01,\n",
       "          7.54000023e-02,  -1.87810004e-01,   4.72680002e-01,\n",
       "          3.60749997e-02,  -2.08690003e-01,  -1.44419998e-01,\n",
       "         -5.36589995e-02,   2.29369998e-02,   2.93720007e-01,\n",
       "          3.57080013e-01,   1.12039998e-01,   1.43769994e-01,\n",
       "         -7.22049996e-02,   3.68640006e-01,   1.83470007e-02,\n",
       "          4.14579988e-01,  -3.15770000e-01,   2.64999986e-01,\n",
       "          1.01779997e-01,  -7.82440007e-01,  -7.70020008e-01,\n",
       "          1.24480002e-01,  -3.56720001e-01,  -7.05970004e-02,\n",
       "         -5.10779977e-01,   6.32059991e-01,  -1.03940003e-01,\n",
       "          3.23139995e-01,  -4.27969992e-01,  -2.92249992e-02,\n",
       "         -5.53030014e-01,  -1.37040004e-01,  -8.14509988e-02,\n",
       "         -8.35940018e-02,   3.31569999e-01,  -2.60820001e-01,\n",
       "         -1.64969996e-01,   5.47950007e-02,   1.24559999e-01,\n",
       "          3.69630009e-01,   2.40209997e-01,  -1.46139994e-01,\n",
       "          6.76740035e-02,   4.05299999e-02,  -1.61630005e-01,\n",
       "          1.35609999e-01,   1.24519996e-01,  -1.04999997e-01,\n",
       "          1.38150007e-01,   1.07749999e-01,   6.19509995e-01,\n",
       "         -5.51129989e-02,  -2.22360000e-01,  -1.76880002e-01,\n",
       "          3.77909988e-01,  -2.98869997e-01,   3.14529985e-01,\n",
       "          4.07810003e-01,   7.31490016e-01,   1.19620003e-01,\n",
       "          1.28940001e-01,  -6.23310030e-01,  -4.42299992e-01,\n",
       "         -3.43470007e-01,  -2.00969994e-01,  -3.58179994e-02,\n",
       "         -9.02170002e-01,   4.30720001e-02,   4.52979989e-02,\n",
       "         -2.61799991e-01,  -2.63440013e-01,   2.07420006e-01,\n",
       "          4.05800015e-01,  -7.16620013e-02,  -1.31159997e+00,\n",
       "          3.25899988e-01,   4.34049994e-01,   2.70280004e-01,\n",
       "         -1.61219999e-01,  -2.71890014e-01,  -1.96659997e-01,\n",
       "          4.46300000e-01,  -1.68679997e-01,   9.88830030e-02,\n",
       "         -3.82999986e-01,   5.86300015e-01,  -6.63010031e-02,\n",
       "          5.05019985e-02,  -2.67859995e-01,   2.04689994e-01,\n",
       "         -3.34989995e-01,  -2.99809992e-01,   1.78409994e-01,\n",
       "         -2.02450007e-01,  -2.26769999e-01,  -7.90790021e-02,\n",
       "         -2.32199997e-01,   6.05770014e-02,   3.51999998e-01,\n",
       "         -2.08969995e-01,   2.10490003e-01,  -5.57690024e-01,\n",
       "         -4.48430002e-01,  -2.42899999e-01,  -2.68880010e-01,\n",
       "          5.49679995e-03,   1.00550003e-01,  -1.19400002e-01,\n",
       "         -3.77380013e-01,  -3.87809992e-01,  -3.17649990e-01,\n",
       "          2.30079994e-01,  -5.47479987e-01,   6.27210021e-01,\n",
       "          3.60659987e-01,   4.45519993e-03,  -5.23860008e-03,\n",
       "         -2.52579987e-01,  -2.55149990e-01,  -1.62560001e-01,\n",
       "          6.62100017e-02,   3.72189991e-02,   1.60030007e-01,\n",
       "         -1.13829998e-02,  -1.27979994e-01,  -3.36239994e-01,\n",
       "          5.35340011e-02,  -3.83520007e-01,   3.62159997e-01,\n",
       "          1.60140004e-02,   7.57539988e-01,  -3.18030000e-01,\n",
       "          4.05270010e-01,   1.07129999e-01,  -9.18390043e-03,\n",
       "          2.01759994e-01,   8.89649987e-02,  -7.18400031e-02,\n",
       "          8.69449973e-02,   3.93819988e-01,  -8.64669979e-02,\n",
       "          1.04839997e-02,  -2.48109996e-01,  -5.42940021e-01,\n",
       "         -6.17150009e-01,   9.44159999e-02,  -2.22539995e-02,\n",
       "          2.50660002e-01,   4.25130010e-01,   6.41910017e-01,\n",
       "          4.40690011e-01,  -1.93039998e-01,   1.66889995e-01,\n",
       "         -5.53259999e-02,  -2.84069985e-01,  -3.41949984e-02,\n",
       "          1.96590006e-01,  -1.66700006e-01,   5.17939985e-01,\n",
       "         -4.04170007e-01,   2.43250001e-02,   8.71540010e-02,\n",
       "         -3.12949985e-01,  -4.24740016e-02,   4.53209989e-02,\n",
       "         -2.25960001e-01,  -3.63750011e-01,  -7.14959996e-03,\n",
       "         -8.66480023e-02,  -3.44989985e-01,  -5.38160026e-01,\n",
       "         -2.83389986e-01,  -7.98550025e-02,   1.23410001e-01,\n",
       "          2.44320005e-01,   1.35700004e-02,   4.21640016e-02,\n",
       "          2.49890000e-01,   2.18319997e-01,   1.16260000e-01,\n",
       "         -1.33800000e-01,  -3.31800014e-01,  -1.53190002e-03,\n",
       "          5.12669981e-01,   2.91579992e-01,   2.56570011e-01,\n",
       "         -2.52559990e-01,  -7.40580037e-02,  -2.44650006e-01,\n",
       "         -2.61640012e-01,   2.42679998e-01,   3.12090009e-01,\n",
       "         -3.34890008e-01,   3.50050002e-01,   6.50049970e-02,\n",
       "          9.68720019e-02,  -1.40210003e-01,   1.64700001e-01,\n",
       "         -1.55570000e-01,  -1.26019999e-01,   2.16260001e-01,\n",
       "         -9.94310006e-02,   3.11390013e-01,   7.27999985e-01,\n",
       "          1.23860002e-01,  -1.93169996e-01,  -6.95519984e-01,\n",
       "          1.62489992e-02,  -1.22290002e-02,  -1.41880000e-02,\n",
       "          1.44439995e-01,   2.98200011e-01,  -5.64340018e-02,\n",
       "         -2.26669997e-01,   5.99509999e-02,   3.38739991e-01,\n",
       "         -2.23849993e-02,   5.44570029e-01,  -4.56290007e-01,\n",
       "         -2.76410013e-01,   2.07599998e-01,  -2.80750006e-01,\n",
       "          1.57649994e-01,   4.45859998e-01,  -3.38279992e-01,\n",
       "         -2.24830002e-01,  -4.60339993e-01,  -2.30820000e-01,\n",
       "          9.00140032e-02,   1.36250004e-01,   1.42649993e-01,\n",
       "          6.09639995e-02,  -1.65539995e-01,   1.51470006e-01], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[2456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197276/197276 [00:00<00:00, 638419.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# then create an embedding_matrix, get the 10,000 words from the begining.\n",
    "# fill embedding_matrix with 'values': 300D arrays.\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))   #word_index from previous step\n",
    "embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))   #-> (nb_words + 1, 300)\n",
    "\n",
    "# operation on each <key, value> in dict,\n",
    "for i, j in tqdm(word_index.items()):\n",
    "    if j >= MAX_NB_WORDS:     # 100000\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(str.encode(i))\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[j] = embedding_vector    # shape -> (nb_words + 1, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100001, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.92909998e-02,   2.04830006e-01,  -1.28079996e-01,\n",
       "        -8.66860002e-02,  -1.15840003e-01,  -6.31299987e-02,\n",
       "        -1.11879997e-01,  -1.54929996e-01,  -3.09139997e-01,\n",
       "         3.11120009e+00,  -6.20779991e-02,   8.04390013e-02,\n",
       "         5.18419981e-01,   2.87530005e-01,  -3.38719994e-01,\n",
       "        -1.45840004e-01,  -2.30550006e-01,   7.30069995e-01,\n",
       "        -3.83579999e-01,  -7.46319965e-02,   1.53029993e-01,\n",
       "         7.60390013e-02,   3.25049981e-02,  -4.00179997e-02,\n",
       "        -2.30660006e-01,   1.50299996e-01,  -2.42960006e-01,\n",
       "        -2.32030004e-01,   1.29319996e-01,  -1.65600002e-01,\n",
       "        -3.25379997e-01,   1.02640003e-01,   6.45380020e-02,\n",
       "         1.30840003e-01,  -1.54579999e-02,  -4.31160003e-01,\n",
       "        -5.69970012e-02,  -1.35749996e-01,  -2.85210013e-01,\n",
       "        -3.88619989e-01,  -1.21179998e-01,   3.91189992e-01,\n",
       "         1.14809997e-01,  -8.66649970e-02,   2.26129994e-01,\n",
       "        -2.20759995e-02,  -2.51870006e-01,  -2.18410000e-01,\n",
       "        -1.24140002e-01,   1.35189995e-01,  -1.39809996e-01,\n",
       "        -1.18060000e-01,   1.25790000e-01,   3.29790004e-02,\n",
       "         4.77999985e-01,   2.79789995e-02,  -1.74600005e-01,\n",
       "        -1.68630004e-01,   2.01130006e-02,   1.48350000e-02,\n",
       "        -1.68950006e-01,  -1.50340006e-01,  -4.75010015e-02,\n",
       "         4.25900012e-01,   5.79949990e-02,  -3.67109999e-02,\n",
       "        -1.26540005e-01,  -3.86280008e-02,   1.44989997e-01,\n",
       "        -9.78830010e-02,   2.42420003e-01,   1.29439995e-01,\n",
       "         1.72859997e-01,  -1.42600000e-01,   1.98890001e-01,\n",
       "         4.20410000e-02,   1.58350006e-01,  -2.26459995e-01,\n",
       "         3.53990011e-02,   2.74910003e-01,  -1.30530000e-01,\n",
       "        -1.45249993e-01,  -1.03550002e-01,  -8.20130035e-02,\n",
       "         1.40770003e-01,  -1.16389997e-01,   2.33429998e-01,\n",
       "        -6.07429981e-01,   4.84629989e-01,  -1.60540000e-01,\n",
       "        -2.48209998e-01,  -1.32320002e-01,  -7.49970004e-02,\n",
       "         1.45160004e-01,   1.60569996e-01,  -8.25159997e-03,\n",
       "         1.49790004e-01,  -1.68310001e-01,   5.31780012e-02,\n",
       "         2.98130006e-01,  -3.69849987e-02,   2.01429993e-01,\n",
       "        -6.99110031e-02,  -5.10130003e-02,   1.61349997e-01,\n",
       "        -1.05270004e+00,   1.31990001e-01,  -1.74700007e-01,\n",
       "        -3.18679988e-01,   1.84799999e-01,   1.93670001e-02,\n",
       "        -1.42039999e-01,  -5.87580018e-02,  -7.24819973e-02,\n",
       "         2.94400007e-01,  -4.40099984e-02,   9.72890034e-02,\n",
       "        -3.06419998e-01,   1.10689998e-02,  -3.42309996e-02,\n",
       "         1.93179995e-01,  -1.76980004e-01,  -2.23040003e-02,\n",
       "        -1.58360004e-01,  -1.49790002e-02,   2.23700002e-01,\n",
       "         1.16669998e-01,  -2.63909996e-01,  -4.11639996e-02,\n",
       "         1.64320007e-01,   7.89050013e-02,   1.03249997e-01,\n",
       "        -7.95420036e-02,   2.37880006e-01,   1.68799996e-01,\n",
       "        -5.31949997e-02,  -1.18740000e-01,  -1.14940003e-01,\n",
       "         4.09619994e-02,  -3.37769999e-03,  -1.57099998e+00,\n",
       "         3.37350011e-01,   2.41689995e-01,  -2.85550002e-02,\n",
       "         2.62879997e-01,  -3.85809988e-01,  -2.73209989e-01,\n",
       "        -7.27619976e-02,   1.21849999e-01,  -2.43860006e-01,\n",
       "         8.11759979e-02,   8.46709982e-02,  -9.91439968e-02,\n",
       "         1.61709994e-01,  -1.13360003e-01,  -4.62179989e-01,\n",
       "         6.63009984e-03,  -6.09279983e-02,   2.90709995e-02,\n",
       "         2.24859998e-01,   7.32949972e-02,   1.05710000e-01,\n",
       "        -3.76670003e-01,  -2.19730005e-01,  -2.05679998e-01,\n",
       "        -1.71409994e-01,   1.51419997e-01,  -3.36459994e-01,\n",
       "         3.95130008e-01,   1.45889997e-01,  -3.03350011e-04,\n",
       "         1.24339998e-01,   3.36870015e-01,  -4.24470007e-01,\n",
       "         7.62289986e-02,   6.95419982e-02,   1.66749999e-01,\n",
       "         2.33630002e-01,   2.29560003e-01,  -1.63389996e-01,\n",
       "        -1.34289995e-01,   2.22680002e-01,  -3.34699988e-01,\n",
       "        -2.36080006e-01,  -1.90300003e-01,  -1.82280004e-01,\n",
       "        -1.91060007e-01,  -1.27250001e-01,  -1.37750003e-02,\n",
       "         4.49039996e-01,   1.43110007e-01,   3.28049988e-01,\n",
       "        -5.23720026e-01,  -6.93709999e-02,   2.28259996e-01,\n",
       "         7.86850005e-02,  -2.16209993e-01,  -2.35609993e-01,\n",
       "         1.73659995e-01,   1.99680001e-01,   2.62529999e-01,\n",
       "        -1.08879998e-01,  -9.32520032e-02,  -2.94470012e-01,\n",
       "         2.86489993e-01,   5.42949997e-02,  -6.80439994e-02,\n",
       "        -1.16760001e-01,   1.70959994e-01,   1.27079993e-01,\n",
       "         6.80069998e-02,  -2.31739998e-01,  -1.04709998e-01,\n",
       "        -2.22829998e-01,   2.10759997e-01,   1.92090005e-01,\n",
       "        -2.64840007e-01,   7.71619976e-02,  -1.84430003e-01,\n",
       "        -2.82269996e-02,   1.42440006e-01,   2.45830007e-02,\n",
       "         7.56070018e-02,   6.14660010e-02,  -6.44329982e-03,\n",
       "         1.23860002e-01,   2.08039992e-02,   5.34209982e-02,\n",
       "        -3.28009993e-01,  -1.19099997e-01,  -2.68559992e-01,\n",
       "        -1.47459999e-01,   1.71450004e-01,   1.07029997e-01,\n",
       "        -1.08230002e-01,  -6.69599995e-02,   6.95810020e-02,\n",
       "        -4.09310013e-01,  -7.09969997e-02,   5.27819991e-02,\n",
       "         1.40249997e-01,  -5.50430007e-02,   1.36059999e-01,\n",
       "         2.81029999e-01,   2.12960005e-01,  -3.89479995e-01,\n",
       "        -1.30510002e-01,  -1.21050000e-01,  -2.23470002e-01,\n",
       "         2.49660000e-01,   1.28279999e-02,  -2.94490010e-01,\n",
       "        -1.69650003e-01,   2.26949994e-02,  -1.42690003e-01,\n",
       "         1.51280001e-01,   1.92259997e-03,  -9.21140015e-02,\n",
       "        -4.07220013e-02,   7.19980001e-02,   2.10679993e-01,\n",
       "         3.09610009e-01,   3.17879999e-03,   2.61599988e-01,\n",
       "         2.66730011e-01,   3.07999998e-01,   1.18019998e-01,\n",
       "         1.29620001e-01,   2.64059991e-01,   3.90340000e-01,\n",
       "         5.14429986e-01,   1.09660000e-01,   1.53219998e-01,\n",
       "        -1.14540003e-01,  -2.67399997e-01,  -6.45740032e-02,\n",
       "        -1.08419999e-01,   1.01770004e-02,   6.08600006e-02,\n",
       "         1.50590003e-01,   1.74480006e-01,  -1.52319996e-02,\n",
       "         2.08460003e-01,   1.19280003e-01,  -1.25770003e-01,\n",
       "        -1.63230002e-01,   2.07259998e-01,   1.91479996e-01,\n",
       "         4.27110009e-02,   8.33609998e-02,  -2.36870006e-01,\n",
       "         2.26060003e-01,   1.17449999e-01,   8.38909969e-02,\n",
       "         1.50509998e-01,   1.11670002e-01,  -3.52840006e-01,\n",
       "        -2.85290003e-01,   3.37029994e-01,   1.23350002e-01])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## https://arxiv.org/abs/1512.08756\n",
    "from attention import Attention   # Attention is a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nkeras.layers.Embedding(input_dim,      # Size of the vocabulary, i.e. maximum integer index + 1.\\n                       output_dim,     # Dimension of the dense embedding\\n                       embeddings_initializer='uniform', \\n                       embeddings_regularizer=None, \\n                       activity_regularizer=None, \\n                       embeddings_constraint=None, \\n                       mask_zero=False, \\n                       input_length=None)   #Length of input sequences,\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define LSTM layer:\n",
    "# What is LSTM net:\n",
    "# To reduce the vanishing (and exploding) gradient problem, \n",
    "# and therefore allow deeper networks and recurrent neural networks to perform well in practical settings, \n",
    "# there needs to be a way to reduce the multiplication of gradients which are less than zero. \n",
    "# The LSTM cell is a specifically designed unit of logic \n",
    "# that will help reduce the vanishing gradient problem sufficiently \n",
    "# to make recurrent neural networks more useful for long-term memory tasks.\n",
    "\n",
    "# num_lstm 300\n",
    "# rate_drop_lstm 0.25\n",
    "# definition of keras.layers.LSTM()\n",
    "'''\n",
    "keras.layers.LSTM(units,                 # output dimention\n",
    "                  activation='tanh', \n",
    "                  recurrent_activation='hard_sigmoid', \n",
    "                  use_bias=True, \n",
    "                  kernel_initializer='glorot_uniform', \n",
    "                  recurrent_initializer='orthogonal', \n",
    "                  bias_initializer='zeros', \n",
    "                  unit_forget_bias=True, \n",
    "                  kernel_regularizer=None, \n",
    "                  recurrent_regularizer=None, \n",
    "                  bias_regularizer=None, \n",
    "                  activity_regularizer=None, \n",
    "                  kernel_constraint=None, \n",
    "                  recurrent_constraint=None, \n",
    "                  bias_constraint=None, \n",
    "                  dropout=0.0,           # Fraction of the units to drop for the linear transformation of the inputs.\n",
    "                  recurrent_dropout=0.0, #  Fraction of the units to drop for the linear transformation of the recurrent state.\n",
    "                  implementation=1, \n",
    "                  return_sequences=False,   #Boolean. Whether to return the last output. in the output sequence, or the full sequence.\n",
    "                  return_state=False, \n",
    "                  go_backwards=False, \n",
    "                  stateful=False, \n",
    "                  unroll=False)\n",
    "'''\n",
    "'''\n",
    "keras.layers.Embedding(input_dim,      # Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "                       output_dim,     # Dimension of the dense embedding\n",
    "                       embeddings_initializer='uniform', \n",
    "                       embeddings_regularizer=None, \n",
    "                       activity_regularizer=None, \n",
    "                       embeddings_constraint=None, \n",
    "                       mask_zero=False, \n",
    "                       input_length=None)   #Length of input sequences,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "define embedding layer & lstm layer:\n",
    "'''\n",
    "# embedding_matrix is used here!\n",
    "embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],    # input_dim = nb_words + 1 \n",
    "                            output_dim=embedding_matrix.shape[1],    # output_dim = 300\n",
    "                            weights=[embedding_matrix],   # weight -> [(nb_words + 1, 300)]\n",
    "                            input_length=100,             #\n",
    "                            trainable=False)\n",
    "\n",
    "# LSTM layer:\n",
    "## http://www.bioinf.jku.at/publications/older/2604.pdf\n",
    "lstm_layer = LSTM(num_lstm,   # 300 \n",
    "                  dropout=rate_drop_lstm,   # 0.25\n",
    "                  recurrent_dropout=rate_drop_lstm,\n",
    "                  return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Construct our deep net\n",
    "'''\n",
    "\n",
    "comment_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')  #(100,) ->> (?,100)\n",
    "x = embedding_layer(comment_input)                                  #(?, 100)->> (?, 100, 300)\n",
    "x = lstm_layer(x)                                                   #(?, 100,300) ->> (?,?,300)\n",
    "x = Dropout(rate_drop_dense)(x)                                     #(?,?,300) ->> (?,?,300)\n",
    "x = Attention(MAX_SEQUENCE_LENGTH)(x)                               #(?,?,300) ->> (?,300)\n",
    "# num_dense = 256\n",
    "x = Dense(num_dense, activation='relu')(x)                          #(?,300) ->> (?,256)\n",
    "x = Dropout(rate_drop_dense)(x)                                     #(?,256) ->> (?,256)\n",
    "## https://arxiv.org/abs/1502.03167\n",
    "x = BatchNormalization()(x)                                         #(?,256) ->> (?,256)\n",
    "preds = Dense(6, activation='sigmoid')(x)                           #(?,256) ->> (?,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          30000300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 300)          721200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 300)               400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               77056     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 30,801,522\n",
      "Trainable params: 800,710\n",
      "Non-trainable params: 30,000,812\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Model:\n",
    "model = Model(inputs=[comment_input],   \n",
    "              outputs=preds)     # (?,100) ->> (?,6)\n",
    "\n",
    "# configure the learning process:\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_lstm_glove_vectors_0.25_0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "STAMP = 'simple_lstm_glove_vectors_%.2f_%.2f'%(rate_drop_lstm,rate_drop_dense)\n",
    "print(STAMP)\n",
    "\n",
    "# define: early_stop, model_checkpoint:\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=5)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/3\n",
      "900/900 [==============================] - 14s 15ms/step - loss: 0.7417 - acc: 0.4969 - val_loss: 0.6944 - val_acc: 0.6200\n",
      "Epoch 2/3\n",
      "900/900 [==============================] - 13s 14ms/step - loss: 0.6613 - acc: 0.6556 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 3/3\n",
      "900/900 [==============================] - 12s 14ms/step - loss: 0.6124 - acc: 0.8187 - val_loss: 0.5519 - val_acc: 0.9200\n"
     ]
    }
   ],
   "source": [
    "# training : data_train, labels_train, data_val, labels_val!!!\n",
    "hist = model.fit(final_data_train, labels_train, \n",
    "                 validation_data=(final_data_val, labels_val),   # this is validation data\n",
    "                 epochs=3, \n",
    "                 batch_size=256, \n",
    "                 shuffle=True,\n",
    "                 callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# loads the weights of the model from a HDF5 file (created by 'save_weights'). \n",
    "model.load_weights(bst_model_path)\n",
    "bst_val_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy:\n",
    "acc = np.array(hist.history['acc'])\n",
    "loss = np.array(hist.history['loss'])\n",
    "val_acc = np.array(hist.history['val_loss'])\n",
    "val_loss = np.array(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9db1392e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1,3,3)\n",
    "lines = plt.plot(x, acc, x, loss, x, val_acc, x, val_loss)\n",
    "plt.setp(lines[0], linewidth=1)\n",
    "plt.setp(lines[1], linewidth=2)\n",
    "plt.setp(lines[2], linewidth=3)\n",
    "plt.setp(lines[2], linewidth=4)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"persent\")\n",
    "plt.legend((\"acc\",\"loss\",\"val_acc\",\"val_loss\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f9dd98e76d8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 598s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_data \n",
    "y_test = model.predict([vec_test_data], batch_size=1024, verbose=1)   # ->(1000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999547,  0.92239422,  0.99958783,  0.1934948 ,  0.98634934,\n",
       "         0.70814669],\n",
       "       [ 0.37247682,  0.40909505,  0.3679679 ,  0.41509241,  0.34866887,\n",
       "         0.43134964],\n",
       "       [ 0.34887213,  0.40799153,  0.38453138,  0.41025808,  0.34266198,\n",
       "         0.44540566],\n",
       "       ..., \n",
       "       [ 0.37804866,  0.41520289,  0.37866133,  0.41064742,  0.37390634,\n",
       "         0.46482348],\n",
       "       [ 0.33972353,  0.39041695,  0.37619966,  0.47134393,  0.36521405,\n",
       "         0.4566921 ],\n",
       "       [ 0.61343443,  0.46266419,  0.51645678,  0.40656155,  0.5149222 ,\n",
       "         0.4582178 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./y_test.csv','w') as f:\n",
    "    for _ in y_test:\n",
    "        f.write(str(_))\n",
    "        f.write(' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before submission, use whiole data seet, \n",
    "# submission:\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "sample_submission[labels_list] = y_test\n",
    "\n",
    "\n",
    "# write dataframe to .csv file: without index!\n",
    "sample_submission.to_csv('%.4f_'%(bst_val_score) + STAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DataFrame.to_csv(path_or_buf=None, \n",
    "                 sep=', ', na_rep='', \n",
    "                 float_format=None, columns=None, \n",
    "                 header=True,       ## !!\n",
    "                 index=True,        ## !!\n",
    "                 index_label=None, \n",
    "                 mode='w', encoding=None, \n",
    "                 compression=None, quoting=None, \n",
    "                 quotechar='\"', line_terminator='\\n', \n",
    "                 chunksize=None, tupleize_cols=None, \n",
    "                 date_format=None, doublequote=True, \n",
    "                 escapechar=None, decimal='.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [_ for _ in np.arange(1,10,1)]\n",
    "b = [i for i in np.arange(11,20,1)]\n",
    "c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./tmp.csv','w')\n",
    "count=0\n",
    "for i, j in zip(a,b):\n",
    "    f.write(str(i))\n",
    "    f.write(' ')\n",
    "    f.write(str(j))\n",
    "    f.write('\\n\\n')\n",
    "    count+=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# operatin on each <key, value> in dict:\n",
    "for i,j in dict.items():\n",
    "    #do something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "## after applying clean function,\n",
    "# read cleaned comment, only comment:\n",
    "# add attribute name\n",
    "data = pd.read_csv(\"./cleaned_train_comment.csv\",names=[\"comment_text\"])\n",
    "\n",
    "# keep it in the memory,\n",
    "## data.to_csv(\"./cleaned_train_comment.csv\",index=False)\n",
    "\n",
    "# read original file, replace \"comment_text\" with cleaned \"comment_text\"\n",
    "sample = pd.read_csv(\"./train.csv\")\n",
    "sample[\"comment_text\"] = data\n",
    "# finally write it to file\n",
    "sample.to_csv(\"./full_train_data.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "# get 1000 samples as train_1000.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/junhui/DATA/text_analysis/kaggle\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "train_path = sys.argv[1]          # cleaned comment\n",
    "ori_train_path = sys.argv[2]          # original training data file\n",
    "full_cleaned_path = sys.argv[3]   # file to store fully cleaned data \n",
    "\n",
    "def clean_comment(train_path):\n",
    "    data = pd.read_csv(train_path, names=[\"comment_text\"])\n",
    "\n",
    "    sample = pd.read_csv(ori_train_path)\n",
    "    sample[\"comment_text\"] = data\n",
    "    \n",
    "    sample.to_csv(full_cleaned_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose 1000 piese of data:\n",
    "data = pd.read_csv(\"aaaa.csv\")\n",
    "data_1000 = data.loc[0:1000,:]\n",
    "data_1000.to_csv(\"./train_1000.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"aabb.csv\")\n",
    "data_100 = data.loc[0:100,:]\n",
    "data_100.to_csv(\"./test_100.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
